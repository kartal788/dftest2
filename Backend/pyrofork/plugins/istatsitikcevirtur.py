import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from pymongo import MongoClient, UpdateOne
from collections import defaultdict
import psutil
from pyrogram import Client, filters, enums
from pyrogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from deep_translator import GoogleTranslator
import os

# ---------------- CONFIG ----------------
OWNER_ID = int(os.getenv("OWNER_ID", 12345))
stop_event = asyncio.Event()
DOWNLOAD_DIR = "/"

# ---------------- DATABASE ----------------
db_raw = os.getenv("DATABASE", "")
if not db_raw:
    raise Exception("DATABASE ortam deÄŸiÅŸkeni bulunamadÄ±!")

db_urls = [u.strip() for u in db_raw.split(",") if u.strip()]
MONGO_URL = db_urls[1] if len(db_urls) > 1 else db_urls[0]

client_db = MongoClient(MONGO_URL)
db_name = client_db.list_database_names()[0]
db = client_db[db_name]
movie_col = db["movie"]
series_col = db["tv"]

bot_start_time = time.time()

# ---------------- UTILS ----------------
def translate_text_safe(text, cache):
    if not text or str(text).strip() == "":
        return ""
    if text in cache:
        return cache[text]
    try:
        tr = GoogleTranslator(source='en', target='tr').translate(text)
    except:
        tr = text
    cache[text] = tr
    return tr

def progress_bar(current, total, bar_length=12):
    if total == 0:
        return "[â¬¡" + "â¬¡"*(bar_length-1) + "] 0.00%"
    percent = (current / total) * 100
    filled_length = int(bar_length * current // total)
    bar = "â¬¢" * filled_length + "â¬¡" * (bar_length - filled_length)
    return f"[{bar}] {min(percent,100):.2f}%"

def format_time_custom(total_seconds):
    if total_seconds is None or total_seconds < 0:
        return "0s0d00s"
    total_seconds = int(total_seconds)
    h, rem = divmod(total_seconds, 3600)
    m, s = divmod(rem, 60)
    return f"{h}s{m}d{s:02}s"

async def handle_stop(callback_query: CallbackQuery):
    stop_event.set()
    try:
        await callback_query.message.edit_text(
            "â›” Ä°ÅŸlem **iptal edildi**!",
            parse_mode=enums.ParseMode.MARKDOWN
        )
        await callback_query.answer("Durdurma talimatÄ± alÄ±ndÄ±.")
    except:
        pass

# ---------------- GLOBAL FLAGS ----------------
is_running = False
stop_event = asyncio.Event()

# ---------------- TRANSLATE WORKER ----------------
def translate_batch_worker(batch_docs):
    """
    Batch olarak gelen belgeleri Ã§evirir.
    Her doc {'_id': ..., 'title': ..., 'description': ..., 'seasons': [...]} yapÄ±sÄ±nda olmalÄ±dÄ±r.
    """
    CACHE = {}
    results = []
    errors = []

    for doc in batch_docs:
        _id = doc.get("_id")
        upd = {}
        title_main = doc.get("title") or doc.get("name") or "Ä°sim yok"

        try:
            # Film description Ã§evirisi
            if "description" in doc and doc["description"]:
                upd["description"] = translate_text_safe(doc["description"], CACHE)

            # Dizi sezonlarÄ± ve bÃ¶lÃ¼mleri
            seasons = doc.get("seasons")
            if seasons:
                for s in seasons:
                    for ep in s.get("episodes", []):
                        if not ep.get("cevrildi", False):
                            if ep.get("title"):
                                ep["title"] = translate_text_safe(ep["title"], CACHE)
                            if ep.get("overview"):
                                ep["overview"] = translate_text_safe(ep["overview"], CACHE)
                            ep["cevrildi"] = True
                upd["seasons"] = seasons

            upd["cevrildi"] = True
            results.append((_id, upd))
        except Exception as e:
            errors.append(f"ID: {_id} | Film/Dizi: {title_main} | Hata: {str(e)}")

    return results, errors


# ---------------- /cevir ----------------
@Client.on_message(filters.command("cevir") & filters.private & filters.user(OWNER_ID))
async def cevir(client: Client, message: Message):
    global stop_event, is_running

    if is_running:
        await message.reply_text("â›” Zaten devam eden bir iÅŸlem var.")
        return

    is_running = True
    stop_event.clear()

    start_msg = await message.reply_text(
        "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Ã§eviri hazÄ±rlanÄ±yor...\nÄ°lerleme tek mesajda gÃ¶sterilecektir.",
        parse_mode=enums.ParseMode.MARKDOWN,
        reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("âŒ Ä°ptal Et", callback_data="stop")]]),
    )

    start_time = time.time()

    # ---------------- TOPLAM HESAPLAMA ----------------
    movies_to_translate = movie_col.count_documents({})
    episodes_to_translate = 0
    for doc in series_col.find({}, {"seasons.episodes": 1}):
        for season in doc.get("seasons", []):
            episodes_to_translate += len(season.get("episodes", []))

    total_to_translate = movies_to_translate + episodes_to_translate
    translated_movies = 0
    translated_episodes = 0
    error_count = 0

    collections = [
        {"col": movie_col, "type": "film", "translated": 0, "errors_list": []},
        {"col": series_col, "type": "episode", "translated": 0, "errors_list": []},
    ]

    batch_size = 50
    workers = 4
    pool = ThreadPoolExecutor(max_workers=workers)
    loop = asyncio.get_event_loop()
    last_update = time.time()
    update_interval = 10

    try:
        for c in collections:
            col = c["col"]
            docs_cursor = col.find({}, {"_id": 1})
            ids = [d["_id"] for d in docs_cursor]
            idx = 0

            while idx < len(ids):
                if stop_event.is_set():
                    break

                batch_ids = ids[idx: idx + batch_size]
                batch_docs = list(col.find({"_id": {"$in": batch_ids}}))

                # Worker Ã§aÄŸrÄ±sÄ±
                results, errors = await loop.run_in_executor(pool, translate_batch_worker, batch_docs)

                for _id, upd in results:
                    try:
                        col.update_one({"_id": _id}, {"$set": upd})
                        if c["type"] == "film":
                            translated_movies += 1
                        else:
                            seasons = upd.get("seasons", [])
                            ep_count = sum(len(s.get("episodes", [])) for s in seasons)
                            translated_episodes += ep_count
                    except:
                        errors.append(f"ID: {_id} | DB GÃ¼ncelleme HatasÄ±")

                error_count += len(errors)
                c["errors_list"].extend(errors)
                idx += len(batch_ids)

                # ---------------- CPU / RAM ----------------
                cpu = psutil.cpu_percent(interval=None)
                ram = psutil.virtual_memory().percent

                # ---------------- SÃœRE HESAPLAMA ----------------
                elapsed = int(time.time() - start_time)
                h, rem = divmod(elapsed, 3600)
                m, s = divmod(rem, 60)
                elapsed_str = f"{h}s{m}d{s}s"

                remaining = (movies_to_translate - translated_movies) + (episodes_to_translate - translated_episodes)
                eta_str = "hesaplanÄ±yor"
                if translated_movies + translated_episodes > 0:
                    avg = elapsed / (translated_movies + translated_episodes)
                    eta_sec = int(avg * remaining)
                    eh, er = divmod(eta_sec, 3600)
                    em, es = divmod(er, 60)
                    eta_str = f"{eh}s{em}d{es}s"

                if time.time() - last_update >= update_interval or idx >= len(ids):
                    last_update = time.time()
                    try:
                        await start_msg.edit_text(
                            (
                                f"ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Ã§eviri yapÄ±lÄ±yor.\n\n"
                                f"Toplam: {total_to_translate} (Film {movies_to_translate} | BÃ¶lÃ¼m {episodes_to_translate})\n"
                                f"Ã‡evrilen: Film {translated_movies} | BÃ¶lÃ¼m {translated_episodes}\n"
                                f"Kalan: Film {movies_to_translate - translated_movies} | BÃ¶lÃ¼m {episodes_to_translate - translated_episodes}\n"
                                f"HatalÄ±: {error_count}\n"
                                f"{progress_bar(translated_movies + translated_episodes, total_to_translate)}\n\n"
                                f"SÃ¼re: `{elapsed_str}` (`{eta_str}`)\n\n"
                                f"â”Ÿ CPU â†’ {cpu}%\n"
                                f"â”– RAM â†’ {ram}%"
                            ),
                            parse_mode=enums.ParseMode.MARKDOWN,
                            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("âŒ Ä°ptal Et", callback_data="stop")]]),
                        )
                    except:
                        pass
    finally:
        pool.shutdown(wait=False)
        is_running = False

    # ---------------- FINAL Ã–ZET ----------------
    total_duration = int(time.time() - start_time)
    h, rem = divmod(total_duration, 3600)
    m, s = divmod(rem, 60)
    duration_str = f"{h}s{m}d{s}s"

    cpu = psutil.cpu_percent(interval=1)
    ram = psutil.virtual_memory().percent

    await start_msg.edit_text(
        (
            "ğŸ“Š **Genel Ã–zet**\n\n"
            f"Toplam: {total_to_translate} (Film {movies_to_translate} | BÃ¶lÃ¼m {episodes_to_translate})\n"
            f"Ã‡evrilen: Film {translated_movies} | BÃ¶lÃ¼m {translated_episodes}\n"
            f"Kalan: Film {movies_to_translate - translated_movies} | BÃ¶lÃ¼m {episodes_to_translate - translated_episodes}\n"
            f"HatalÄ±: {error_count}\n"
            f"SÃ¼re: {duration_str}\n\n"
            f"CPU: {cpu}% | RAM: {ram}%"
        ),
        parse_mode=enums.ParseMode.MARKDOWN
    )

    # -------- HATA DOSYASI --------
    hata_icerigi = []
    for c in collections:
        if c["errors_list"]:
            hata_icerigi.append(f"*** {c['col'].name} HatalarÄ± ***")
            hata_icerigi.extend(c["errors_list"])
            hata_icerigi.append("")

    if hata_icerigi:
        log_path = "cevirhatalari.txt"
        with open(log_path, "w", encoding="utf-8") as f:
            f.write("\n".join(hata_icerigi))
        try:
            await client.send_document(
                chat_id=OWNER_ID,
                document=log_path,
                caption="â›” Ã‡eviri sÄ±rasÄ±nda hatalar oluÅŸtu"
            )
        except:
            pass


# ---------------- /cevirekle ----------------
@Client.on_message(filters.command("cevirekle") & filters.private & filters.user(OWNER_ID))
async def cevirekle(client: Client, message: Message):
    status = await message.reply_text("ğŸ”„ 'cevrildi' alanlarÄ± ekleniyor...")
    total_updated = 0

    for col in (movie_col, series_col):
        # Ãœst seviye belgeler
        docs_cursor = col.find({"cevrildi": {"$ne": True}}, {"_id": 1})
        bulk_ops = [UpdateOne({"_id": doc["_id"]}, {"$set": {"cevrildi": True}}) for doc in docs_cursor]

        # Dizi bÃ¶lÃ¼mleri iÃ§in
        if col == series_col:
            docs_cursor = col.find({"seasons.episodes.cevrildi": {"$ne": True}}, {"_id": 1})
            for doc in docs_cursor:
                bulk_ops.append(
                    UpdateOne(
                        {"_id": doc["_id"]},
                        {"$set": {"seasons.$[].episodes.$[].cevrildi": True}}
                    )
                )

        if bulk_ops:
            res = col.bulk_write(bulk_ops)
            total_updated += res.modified_count

    await status.edit_text(f"âœ… 'cevrildi' alanlarÄ± eklendi.\nToplam gÃ¼ncellenen kayÄ±t: {total_updated}")

@Client.on_message(filters.command("cevirkaldir") & filters.private & filters.user(OWNER_ID))
async def cevirkaldir(client: Client, message: Message):
    status = await message.reply_text("ğŸ”„ 'cevrildi' alanlarÄ± kaldÄ±rÄ±lÄ±yor...")
    total_updated = 0

    for col in (movie_col, series_col):
        # Ãœst seviye belgeler
        docs_cursor = col.find({"cevrildi": True}, {"_id": 1})
        bulk_ops = [UpdateOne({"_id": doc["_id"]}, {"$unset": {"cevrildi": ""}}) for doc in docs_cursor]

        # Dizi bÃ¶lÃ¼mleri iÃ§in
        if col == series_col:
            docs_cursor = col.find({"seasons.episodes.cevrildi": True}, {"_id": 1})
            for doc in docs_cursor:
                bulk_ops.append(
                    UpdateOne(
                        {"_id": doc["_id"]},
                        {"$unset": {"seasons.$[].episodes.$[].cevrildi": ""}}
                    )
                )

        if bulk_ops:
            res = col.bulk_write(bulk_ops)
            total_updated += res.modified_count

    await status.edit_text(f"âœ… 'cevrildi' alanlarÄ± kaldÄ±rÄ±ldÄ±.\nToplam gÃ¼ncellenen kayÄ±t: {total_updated}")

# ---------------- /TUR ----------------
@Client.on_message(filters.command("tur") & filters.private & filters.user(OWNER_ID))
async def tur_komutu(client: Client, message: Message):
    start_msg = await message.reply_text("ğŸ”„ TÃ¼r gÃ¼ncellemesi baÅŸlatÄ±ldÄ±â€¦")

    genre_map = {
        "Action": "Aksiyon", "Film-Noir": "Kara Film", "Game-Show": "Oyun GÃ¶sterisi", "Short": "KÄ±sa",
        "Sci-Fi": "Bilim Kurgu", "Sport": "Spor", "Adventure": "Macera", "Animation": "Animasyon",
        "Biography": "Biyografi", "Comedy": "Komedi", "Crime": "SuÃ§", "Documentary": "Belgesel",
        "Drama": "Dram", "Family": "Aile", "News": "Haberler", "Fantasy": "Fantastik",
        "History": "Tarih", "Horror": "Korku", "Music": "MÃ¼zik", "Musical": "MÃ¼zikal",
        "Mystery": "Gizem", "Romance": "Romantik", "Science Fiction": "Bilim Kurgu",
        "TV Movie": "TV Filmi", "Thriller": "Gerilim", "War": "SavaÅŸ", "Western": "VahÅŸi BatÄ±",
        "Action & Adventure": "Aksiyon ve Macera", "Kids": "Ã‡ocuklar", "Reality": "GerÃ§eklik",
        "Reality-TV": "GerÃ§eklik", "Sci-Fi & Fantasy": "Bilim Kurgu ve Fantazi", "Soap": "Pembe Dizi",
        "War & Politics": "SavaÅŸ ve Politika", "Bilim-Kurgu": "Bilim Kurgu",
        "Aksiyon & Macera": "Aksiyon ve Macera", "SavaÅŸ & Politik": "SavaÅŸ ve Politika",
        "Bilim Kurgu & Fantazi": "Bilim Kurgu ve Fantazi", "Talk": "Talk-Show"
    }

    collections = [(movie_col, "Filmler"), (series_col, "Diziler")]
    total_fixed = 0

    for col, name in collections:
        docs_cursor = col.find({}, {"_id": 1, "genres": 1})
        bulk_ops = []

        for doc in docs_cursor:
            doc_id = doc["_id"]
            genres = doc.get("genres", [])
            new_genres = [genre_map.get(g, g) for g in genres]
            if new_genres != genres:
                bulk_ops.append(UpdateOne({"_id": doc_id}, {"$set": {"genres": new_genres}}))
                total_fixed += 1

        if bulk_ops:
            col.bulk_write(bulk_ops)

    await start_msg.edit_text(f"âœ… TÃ¼r gÃ¼ncellemesi tamamlandÄ±.\nToplam deÄŸiÅŸtirilen kayÄ±t: {total_fixed}")

# ---------------- /PLATFORMEKLE ----------------
@Client.on_message(filters.command("platformekle") & filters.private & filters.user(OWNER_ID))
async def platform_ekle(client: Client, message: Message):
    start_msg = await message.reply_text("ğŸ”„ Platform ekleme baÅŸlatÄ±ldÄ±â€¦")

    platform_map = {
        "MAX": "Max", "Hbomax": "Max", "TABÄ°Ä°": "Tabii", "NF": "Netflix", "DSNP": "Disney",
        "Tod": "Tod", "Blutv": "Max", "Tv+": "Tv+", "Exxen": "Exxen",
        "Gain": "Gain", "HBO": "Max", "Tabii": "Tabii", "AMZN": "Amazon",
    }

    collections = [(movie_col, "Filmler"), (series_col, "Diziler")]
    total_fixed = 0

    for col, name in collections:
        docs_cursor = col.find({}, {"_id": 1, "telegram": 1, "seasons": 1})
        bulk_ops = []

        for doc in docs_cursor:
            doc_id = doc["_id"]
            platforms = doc.get("platform", [])
            updated = False

            # Telegram alanÄ± Ã¼zerinden platform ekle
            for t in doc.get("telegram", []):
                name_field = t.get("name", "").lower()
                for key, val in platform_map.items():
                    if key.lower() in name_field and val not in platforms:
                        platforms.append(val)
                        updated = True

            # Sezonlardaki telegram kontrolleri
            for season in doc.get("seasons", []):
                for ep in season.get("episodes", []):
                    for t in ep.get("telegram", []):
                        name_field = t.get("name", "").lower()
                        for key, val in platform_map.items():
                            if key.lower() in name_field and val not in platforms:
                                platforms.append(val)
                                updated = True

            if updated:
                bulk_ops.append(UpdateOne({"_id": doc_id}, {"$set": {"platform": platforms}}))
                total_fixed += 1

        if bulk_ops:
            col.bulk_write(bulk_ops)

    await start_msg.edit_text(f"âœ… Platform ekleme tamamlandÄ±.\nToplam deÄŸiÅŸtirilen kayÄ±t: {total_fixed}")

# ---------------- /PLATFORMSIL ----------------
@Client.on_message(filters.command("platformsil") & filters.private & filters.user(OWNER_ID))
async def platform_sil(client: Client, message: Message):
    start_msg = await message.reply_text("ğŸ”„ Platform kayÄ±tlarÄ± siliniyorâ€¦")
    total_fixed = 0

    collections = [movie_col, series_col]

    for col in collections:
        docs_cursor = col.find({"platform": {"$exists": True}}, {"_id": 1})
        bulk_ops = []

        for doc in docs_cursor:
            doc_id = doc["_id"]
            bulk_ops.append(UpdateOne({"_id": doc_id}, {"$unset": {"platform": ""}}))
            total_fixed += 1

        if bulk_ops:
            col.bulk_write(bulk_ops)

    await start_msg.edit_text(f"âœ… Platform kayÄ±tlarÄ± silindi.\nToplam deÄŸiÅŸtirilen kayÄ±t: {total_fixed}")

# ---------------- /ISTATISTIK ----------------
@Client.on_message(filters.command("istatistik") & filters.private & filters.user(OWNER_ID))
async def istatistik(client: Client, message: Message):
    total_movies = movie_col.count_documents({})
    total_series = series_col.count_documents({})

    def count_links_qualities(collection, is_series=False):
        link_set = set()
        telegram_set = set()
        quality_count = defaultdict(lambda: {"Link": 0, "Telegram": 0})

        if is_series:
            for doc in collection.find({}, {"seasons.episodes.telegram": 1}):
                for season in doc.get("seasons", []):
                    for ep in season.get("episodes", []):
                        for t in ep.get("telegram", []):
                            _id = t.get("id", "")
                            q = t.get("quality", "Unknown")
                            if _id.startswith("http://") or _id.startswith("https://"):
                                if _id not in link_set:
                                    link_set.add(_id)
                                    quality_count[q]["Link"] += 1
                            else:
                                if _id not in telegram_set:
                                    telegram_set.add(_id)
                                    quality_count[q]["Telegram"] += 1
        else:
            for doc in collection.find({}, {"telegram": 1}):
                for t in doc.get("telegram", []):
                    _id = t.get("id", "")
                    q = t.get("quality", "Unknown")
                    if _id.startswith("http://") or _id.startswith("https://"):
                        if _id not in link_set:
                            link_set.add(_id)
                            quality_count[q]["Link"] += 1
                    else:
                        if _id not in telegram_set:
                            telegram_set.add(_id)
                            quality_count[q]["Telegram"] += 1
        return len(link_set), len(telegram_set), dict(quality_count)

    movie_link, movie_tg, movie_quality_counts = count_links_qualities(movie_col)
    series_link, series_tg, series_quality_counts = count_links_qualities(series_col, is_series=True)

    def format_quality_stats(q_dict):
        order = ["2160p", "1920p", "1440p", "1080p", "720p", "576p", "480p"]
        sorted_items = sorted(
            q_dict.items(),
            key=lambda x: (order.index(x[0]) if x[0] in order else len(order), x[0])
        )
        return "\n".join(
            f"   â”  {q} â†’ Link: {c['Link']} | Telegram: {c['Telegram']}"
            for q, c in sorted_items
        )

    cpu = psutil.cpu_percent(interval=1)
    ram = psutil.virtual_memory().percent
    disk = psutil.disk_usage("/")
    free_disk_gb = round(disk.free / (1024**3), 2)
    free_percent = disk.percent

    # -------- BOT UPTIME + YENÄ° GÃ–STERÄ°M KURALLARI --------
    uptime_seconds = int(time.time() - bot_start_time)
    days, rem = divmod(uptime_seconds, 86400)
    hours, rem = divmod(rem, 3600)
    minutes, seconds = divmod(rem, 60)

    if days >= 1:
        uptime_str = f"{days}g{hours}s{minutes}d{seconds}s"
    elif hours >= 1:
        uptime_str = f"{hours}s{minutes}d{seconds}s"
    else:
        uptime_str = f"{minutes}d{seconds}s"
    # -----------------------------------------------------

    stats = db.command("dbstats")
    storage_mb = round(stats.get("storageSize", 0) / (1024 * 1024), 2)
    storage_percent = round((storage_mb / 512) * 100, 1)

    genre_stats = defaultdict(lambda: {"film": 0, "dizi": 0})
    for d in movie_col.aggregate([{"$unwind": "$genres"}, {"$group": {"_id": "$genres", "count": {"$sum": 1}}}]):
        genre_stats[d["_id"]]["film"] = d["count"]
    for d in series_col.aggregate([{"$unwind": "$genres"}, {"$group": {"_id": "$genres", "count": {"$sum": 1}}}]):
        genre_stats[d["_id"]]["dizi"] = d["count"]

    genre_text = "\n".join(
        f"{g:<14} | Film: {c['film']:<4} | Dizi: {c['dizi']:<4}"
        for g, c in sorted(genre_stats.items())
    )

    text = (
        f"âŒ¬ <b>Ä°statistik</b>\n\n"
        f"â”  Filmler : {total_movies}\n"
        f"â”ƒ  â”  Link     : {movie_link}\n"
        f"â”ƒ  â”– Telegram : {movie_tg}\n"
        f"{format_quality_stats(movie_quality_counts)}\n\n"
        f"â”  Diziler : {total_series}\n"
        f"â”ƒ  â”  Link     : {series_link}\n"
        f"â”ƒ  â”– Telegram : {series_tg}\n"
        f"{format_quality_stats(series_quality_counts)}\n\n"
        f"â”– Depolama: {storage_mb} MB (%{storage_percent})\n\n"
        f"<b>TÃ¼r DaÄŸÄ±lÄ±mÄ±</b>\n<pre>{genre_text}</pre>\n\n"
        f"â”Ÿ CPU â†’ {cpu}% | BoÅŸ â†’ {free_disk_gb}GB [{free_percent}%]\n"
        f"â”– RAM â†’ {ram}% | SÃ¼re â†’ {uptime_str}"
    )

    await message.reply_text(text, parse_mode=enums.ParseMode.HTML)

# ---------------- CALLBACK QUERY ----------------
@Client.on_callback_query()
async def _cb(client: Client, query: CallbackQuery):
    if query.data=="stop":
        await handle_stop(query)
# ---------- benzerleri sil ----------
@Client.on_message(filters.command("aynivideolarisil") & filters.private & filters.user(OWNER_ID))
async def benzerleri_sil(client: Client, message: Message):
    status = await message.reply_text("ğŸ” ArÅŸiv taranÄ±yor...")

    total_docs = 0
    total_removed = 0
    log_lines = []

    collections = [
        (movie_col, "movie"),
        (series_col, "tv")
    ]

    for col, col_name in collections:
        cursor = col.find({}, {"telegram": 1, "seasons": 1, "title": 1, "tmdb_id": 1, "imdb_id": 1})

        for doc in cursor:
            doc_updated = False

            # ---------- FILM ----------
            if col_name == "movie" and "telegram" in doc:
                telegram = doc.get("telegram", [])
                grouped = {}

                for idx, t in enumerate(telegram):
                    key = (t.get("name"), t.get("size"))
                    if key not in grouped:
                        grouped[key] = []
                    grouped[key].append((idx, t))

                new_telegram = []

                for (name, size), items in grouped.items():
                    non_http_items = []
                    for i, t in items:
                        tid = str(t.get("id", "")).lower()
                        if not (tid.startswith("http://") or tid.startswith("https://")):
                            non_http_items.append((i, t))

                    if non_http_items:
                        keep_i, keep_t = max(non_http_items, key=lambda x: x[0])
                    else:
                        keep_i, keep_t = max(items, key=lambda x: x[0])

                    new_telegram.append(keep_t)

                    for i, t in items:
                        if t is not keep_t:
                            total_removed += 1
                            doc_updated = True
                            log_lines.append(
                                f"[Koleksiyon] movie\n"
                                f"ID: {doc.get('tmdb_id')}\n"
                                f"BaÅŸlÄ±k: {doc.get('title')}\n"
                                f"Name: {t.get('name')}\n"
                                f"Size: {t.get('size')}\n"
                                f"id: {t.get('id')}\n"
                                f"{'-'*50}"
                            )

                if doc_updated:
                    col.update_one(
                        {"_id": doc["_id"]},
                        {"$set": {"telegram": new_telegram}}
                    )
                    total_docs += 1

            # ---------- DÄ°ZÄ° / BÃ–LÃœM ----------
            if col_name == "tv":
                seasons = doc.get("seasons", [])

                for season in seasons:
                    season_no = season.get("season_number")
                    episodes = season.get("episodes", [])

                    for ep in episodes:
                        if "telegram" not in ep:
                            continue

                        telegram = ep.get("telegram", [])
                        grouped = {}

                        for idx, t in enumerate(telegram):
                            key = (t.get("name"), t.get("size"))
                            if key not in grouped:
                                grouped[key] = []
                            grouped[key].append((idx, t))

                        new_telegram = []

                        for (name, size), items in grouped.items():
                            non_http_items = []
                            for i, t in items:
                                tid = str(t.get("id", "")).lower()
                                if not (tid.startswith("http://") or tid.startswith("https://")):
                                    non_http_items.append((i, t))

                            if non_http_items:
                                keep_i, keep_t = max(non_http_items, key=lambda x: x[0])
                            else:
                                keep_i, keep_t = max(items, key=lambda x: x[0])

                            new_telegram.append(keep_t)

                            for i, t in items:
                                if t is not keep_t:
                                    total_removed += 1
                                    doc_updated = True
                                    log_lines.append(
                                        f"[Koleksiyon] tv\n"
                                        f"ID: {doc.get('imdb_id')}\n"
                                        f"Dizi: {doc.get('title')}\n"
                                        f"Sezon: {season_no} | BÃ¶lÃ¼m: {ep.get('episode_number')}\n"
                                        f"Name: {t.get('name')}\n"
                                        f"Size: {t.get('size')}\n"
                                        f"id: {t.get('id')}\n"
                                        f"{'-'*50}"
                                    )

                        if doc_updated:
                            ep["telegram"] = new_telegram

                if doc_updated:
                    col.update_one(
                        {"_id": doc["_id"]},
                        {"$set": {"seasons": seasons}}
                    )
                    total_docs += 1

    # ---------- LOG DOSYASI ----------
    if log_lines:
        log_path = "silinenler.txt"
        with open(log_path, "w", encoding="utf-8") as f:
            f.write("\n".join(log_lines))

        await client.send_document(
            chat_id=OWNER_ID,
            document=log_path,
            caption="ğŸ—‘ï¸ Silinen videolar"
        )

    await status.edit_text(
        f"âœ… Ä°ÅŸlem tamamlandÄ±\n\n"
        f"ğŸ“„ Etkilenen kayÄ±t: {total_docs}\n"
        f"ğŸ—‘ï¸ Silinen videolar: {total_removed}"
    )


# ---------- linkleri sil ----------
@Client.on_message(filters.command("linklerisil") & filters.private & filters.user(OWNER_ID))
async def linklerisil(client: Client, message: Message):
    status = await message.reply_text("ğŸ”„ Link kayÄ±tlarÄ± temizleniyor...")
    total_removed = 0
    total_docs = 0

    def is_valid_id(tid):
        return not (str(tid).startswith("http://") or str(tid).startswith("https://"))

    # ---------- FILMLER ----------
    for doc in movie_col.find({}, {"_id": 1, "telegram": 1, "title": 1, "tmdb_id":1}):
        telegram = doc.get("telegram", [])
        new_telegram = [t for t in telegram if is_valid_id(t.get("id", ""))]
        removed_count = len(telegram) - len(new_telegram)
        if removed_count > 0:
            total_removed += removed_count
            if new_telegram:
                movie_col.update_one({"_id": doc["_id"]}, {"$set": {"telegram": new_telegram}})
            else:
                movie_col.delete_one({"_id": doc["_id"]})
            total_docs += 1

    # ---------- DÄ°ZÄ°LER ----------
    for doc in series_col.find({}, {"_id": 1, "seasons": 1, "title":1, "imdb_id":1}):
        seasons = doc.get("seasons", [])
        doc_updated = False
        for season in seasons:
            episodes = season.get("episodes", [])
            new_episodes = []
            for ep in episodes:
                telegram = ep.get("telegram", [])
                new_telegram = [t for t in telegram if is_valid_id(t.get("id", ""))]
                removed_count = len(telegram) - len(new_telegram)
                if removed_count > 0:
                    total_removed += removed_count
                if new_telegram:
                    ep["telegram"] = new_telegram
                    new_episodes.append(ep)
                else:
                    doc_updated = True  # bÃ¶lÃ¼m silindi
            season["episodes"] = new_episodes
        # Sezonlar gÃ¼ncellendikten sonra hiÃ§bir bÃ¶lÃ¼m kalmamÄ±ÅŸsa dizi silinecek
        remaining_eps = sum(len(s.get("episodes", [])) for s in seasons)
        if remaining_eps > 0:
            series_col.update_one({"_id": doc["_id"]}, {"$set": {"seasons": seasons}})
            if doc_updated:
                total_docs += 1
        else:
            series_col.delete_one({"_id": doc["_id"]})
            total_docs += 1

    await status.edit_text(f"âœ… Ä°ÅŸlem tamamlandÄ±\n\nğŸ“„ Etkilenen kayÄ±t: {total_docs}\nğŸ—‘ï¸ Silinen tekrar: {total_removed}")
